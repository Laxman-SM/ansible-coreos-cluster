- debug: var=vpc_id

# set facts with file content for cloud-config
# gaia CA crt content
- set_fact:
    gaia_ca_crt_file: "keys/{{ ec2_region }}/{{ gaia_ca_file }}.crt"
- stat:
    path: "{{ gaia_ca_crt_file }}"
  register: st_out
- fail:
    msg: "Missing {{ gaia_ca_crt_file }} file. Please copy this file from ansible-bastion or make the keys directory a symlink"
  when: st_out.stat.exists != True
- shell: "openssl enc -base64 -A -in {{ gaia_ca_crt_file }}"
  register: gaia_ca_crt_content_out
- set_fact:
    gaia_ca_crt_content: "{{ gaia_ca_crt_content_out.stdout }}"
# gaia CA private key content
- set_fact:
    gaia_ca_key_file: "keys/{{ ec2_region }}/{{ gaia_ca_file }}.key"
- stat:
    path: "{{ gaia_ca_key_file }}"
  register: st_out
- fail:
    msg: "Missing {{ gaia_ca_key_file }} file. Please copy this file from ansible-bastion or make the keys directory a symlink"
  when: st_out.stat.exists != True
- shell: "openssl enc -base64 -A -in {{ gaia_ca_key_file }}"
  register: gaia_ca_key_content_out
- set_fact:
    gaia_ca_key_content: "{{ gaia_ca_key_content_out.stdout }}"

# gaia-pubring.gpg content
- set_fact:
    gaia_pubring_file: "keys/gaia-pubring.gpg"
- stat:
    path: "{{ gaia_pubring_file }}"
  register: st_out
- fail:
    msg: "Missing {{ gaia_pubring_file }} file"
  when: st_out.stat.exists != True
- shell: "openssl enc -base64 -A -in {{ gaia_pubring_file }}"
  register: gaia_pubring_content_out
- set_fact:
    gaia_pubring_content: "{{ gaia_pubring_content_out.stdout }}"

# gaia-secring.gpg content
- set_fact:
    gaia_secring_file: "keys/gaia-secring.gpg"
- stat:
    path: "{{ gaia_secring_file }}"
  register: st_out
- fail:
    msg: "Missing {{ gaia_secring_file }} file"
  when: st_out.stat.exists != True
- shell: "openssl enc -base64 -A -in {{ gaia_secring_file }}"
  register: gaia_secring_content_out
- set_fact:
    gaia_secring_content: "{{ gaia_secring_content_out.stdout }}"

- name: Create the security group for the Elasticsearch cluster
  ec2_group:
    name: "{{ elasticsearch_security_group.name }}"
    description: "{{ elasticsearch_security_group.desc }}"
    vpc_id: "{{ vpc_id }}"
    region: "{{ ec2_region }}"
    rules: "{{ elasticsearch_security_group.rules }}"
  register: elasticsearch_sg

- debug: var=elasticsearch_sg

# generate user-data from template
- name: create template
  template: src='user-data.j2' dest='/tmp/elasticsearch-data.txt'
- name: load user-data content
  set_fact:
    # user_data: "{{ lookup('file', '/tmp/elasticsearch-data.txt') | b64encode }}" <-- base64 encoded user-data is not recognized by CoreOS
    user_data: "{{ lookup('file', '/tmp/elasticsearch-data.txt') }}"

# search for latest CoreOS AMI from alpha/beta/stable channel
- name: search for the latest CoreOS AMI image from "{{ coreos_channel }}"
  ec2_ami_find:
    region: "{{ ec2_region }}"
    name: "CoreOS-{{coreos_channel}}-{{coreos_version}}-hvm"
    virtualization_type: hvm
    sort: name
    sort_order: descending
    sort_end: 1
    no_result_action: fail
  register: find_out
- name: get CoreOS AMI for RabbitMQ
  set_fact:
    elasticsearch_ami: "{{ find_out.results[0] }}"

# using JSON file as a workaround for Ansible bug: https://github.com/ansible/ansible/issues/9362
- name: create internal RabbitMQ volume json template
  template: src='volume.j2' dest='/tmp/elasticsearch_volume.json'

# create RabbitMQ launch configuration
# note: for flannel use manually create role with required pilicies
#       https://coreos.com/flannel/docs/latest/vpc-backend.html
- name: create RabbitMQ  launch configuration
  shell: "aws autoscaling create-launch-configuration --launch-configuration-name '{{ elasticsearch_lc_name }}' --key-name '{{ coreos_keypair_name }}' --image-id '{{ elasticsearch_ami.ami_id }}' --security-groups '{{ elasticsearch_sg.group_id }}' --instance-type '{{ elasticsearch_instance_type }}' --iam-instance-profile '{{ coreos_instance_profile }}' --user-data 'file:///tmp/elasticsearch-data.txt' --block-device-mappings 'file:///tmp/elasticsearch_volume.json'"

# create RabbitMQ autoscale group
- name: create RabbitMQ autoscale group
  ec2_asg:
    name: "{{ elasticsearch_asg_name }}"
    region: "{{ ec2_region }}"
    launch_config_name: "{{ elasticsearch_lc_name }}"
    health_check_period: "{{ elasticsearch_health_check_period }}"
    desired_capacity: "{{ elasticsearch_cluster_size }}"
    min_size: "{{ elasticsearch_cluster_size }}"
    max_size: "{{ elasticsearch_max_cluster_size }}"
    tags: "{{ elasticsearch_instance_tags }}"
    vpc_zone_identifier: "{{ vpc_private_subnets }}"
    wait_for_instances: yes
  register: elasticsearch_asg_out

- name: Turn off "source destination check" - needed for flunnel
  local_action: command aws ec2 modify-instance-attribute --region {{ ec2_region }} --instance-id {{ item }} --no-source-dest-check
  with_items: "{{ elasticsearch_asg_out.instances }}"

